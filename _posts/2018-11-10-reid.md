---
title: 如何基于Gluon训练一个强有力的Reid Baseline
author: 赖申其 美团点评智能技术中心 
---

## 简介
这两年，行人再识别得到很多关注，仅 CVPR 2018上，就录取了31篇文章。本文主要是对行人再识别的 Baseline 做一个总结、整理和改进，最终在 Market1501 数据集上达到93.1的 Rank1 和80.3的 mAP，该 Baseline 已经超越2018年大多数顶会录取文章的性能。在实验中，以 Resnet50 作为 Backbone，损失函数采用单个 Softmax loss。我们希望这个 Baseline 能促使整个领域更好地发展，也希望大家能够以此为基础做出更好的工作。

## 框架简介
首先，我个人把 Reid Baseline的发展分为三个阶段。  
<b>第一阶段</b>，最早起源于郑良老师的[综述文章](https://arxiv.org/abs/1610.02984)中，使用一个普通的 Resnet50，只采用水平翻转这种扩增方式，采用 SGD 的方法，学习率为1e-3，即可得到此结果，大致是在73到75之间不等，后续也尝试更改结构并加入 Dropout，可以进一步做到78左右。具体代码可以参考这个链接[代码](https://github.com/zhunzhong07/IDE-baseline-Market-1501)。该阶段其实就是是参照如何训练分类网络的方法在训练模型。  
<b>第二阶段</b>，也是今年顶会中的部分文章的 Baseline，主要来自于两种核心技术：1.更大的学习率，使用 SGD，通过把学习率从1e-3变为1e-1后，模型更容易收敛，性能也进一步提升，可以达到81左右。2.在抽取特征的层后面，使用一个 Batchnorm，可以大幅度提升性能，大致上是可以做到88左右的，我个人最早是在 Tong Xiao 的代码中[open-reid](https://github.com/Cysu/open-reid)发现这个做法，也曾和张凯鹏聊过，他说人脸识别中很早就有这个 trick，具体究竟谁最早提出，有待进一步补充，[CCL](https://arxiv.org/abs/1801.05678)中也讨论了此种做法。此外，该方法在 Reid 中被大量使用应该是在郑哲东放出的[代码中](https://github.com/layumi/Person_reID_baseline_pytorch)中。  
<b>第三阶段</b>，该阶段是我个人近两年调参经验的大集合吧，通过大量 trick 的堆积，成功把 Baseline 做到93左右，我把 trick 主要分为数据扩增，网络结构，训练方法三个大模块。

## Trick细节
由于对比实验不同，具体涨点需要进一步对比实验确定，我们将大致涨点0.5以内的认为是小幅度，0.5到2之间为中幅度，超过2则为大幅度提升。

### 数据扩增

1.主要采用训练时水平翻转，测试时也同样水平翻转抽取两次特征并求平均。该思路在人脸识别问题中就被大量采用。小幅度提升。  
2.输入图像扩大，来自[PCB](https://link.springer.com/chapter/10.1007%2F978-3-030-01225-0_30)中，将256\*128的输入变为384\*128，性能会提升不少，[shperereid](https://arxiv.org/abs/1807.00537)尝试288\*144，我个人实践的结果并不如384\*128。中幅度提升。  
3.随机擦除，random erasing，通过随机擦除图中的一部分方形区域，减少模型过拟合的情况，具体来自于[文章](https://arxiv.org/abs/1708.04896)文章中。在实际中性能不如接下来的方案提升大。中幅度提升。  
4.随机裁剪，很多人尝试过后会发现性能反而不好，这里有个技巧，就是先补0，然后再裁剪，我个人是把图片缩放到384\*128，然后补0至402\*148，再次随机裁剪为384\*128。具体做法来自于[baseline](https://arxiv.org/abs/1807.11042)，该文章中是把图片resize到256\*128，并补0至276\*148，然后随机裁减至256\*128。我个人的理解是这样既能减少图片过多裁减的信息丢失，又能通过黑边补全减少过拟合。大幅度提升。  


### 网络结构
1.去除最后一个 block 的下采样，使得 feature map 扩大四倍，该方法同样来自于[PCB](https://link.springer.com/chapter/10.1007%2F978-3-030-01225-0_30)中，此做法能够大幅度带来性能提升。feature map 变大，会使得更多的细节信息得以保留。大幅度提升。  
2.去掉之前文章中 bottleneck 的做法，直接将 global average pooling 的输出作为抽取特征，该方法会更好的保留局部信息，此方法依然来自[baseline](https://arxiv.org/abs/1807.11042)。小幅度提升。  
3.使用 batchnorm，但是去掉其中的beta参数，使其无偏移量，该方法使得特征整体分布依然以0为原点，会比直接使用 batchnorm 得到更好性能，实践中，gamma 参数是否去除均可，该 trick 也曾出现在文章[CCL](https://arxiv.org/abs/1801.05678)中，但是文中的解释并不是很到位，需要做进一步探究。大幅度提升。  
4.对于抽取特征所在的层，不使用激活函数relu，relu会导致所有抽取的特征均为正值，相当于检索空间缩小一半。同样，leakyrelu，prelu，switch 等激活函数也会有不等的性能下降。小幅度提升。  
5.对于分类所在的全连接层，去掉它的bias，没有bias之后，损失函数对特征的监督信号会更强烈和直接。小幅度提升。

### 训练方法
1.训练器的选择，我们将 sgd 替换为 adam 算法，一切参数均为默认。对于sgd，一般采用1e-1的初始学习率，对于adam，可以大幅度减少，正常来说，2e-3到4e-3之间的初始学习率是比较合理的。中幅度提升。  
2.参照 gluoncv 中提到的 warm up 策略，我们在前10个 epoch 中采用 warm up ，将学习率从3.5e-6逐渐变为3.5e-4。小幅度提升。  
3.学习率和 epoch 的选择。由于结构中已经没有了 dropout，故而模型有很大可能在训练中会突然崩溃而导致大幅度降低性能，通过实验，我们大致选出了一组合适的超参，一般在 warm up 结束后20个epoch内缩小学习率。在实验中，我们在35，60这两个点上缩小学习率为原来的0.1倍，总计训练80个 epoch。小幅度提升。  
4.Adam 配合更小的 batch size。关于 batch size 的选择，对于 sgd 算法，一般使用更大的学习率搭配更大的 batch size，可以使用128，而在本实验中，我们使用 adam 算法，adam 收敛更快，但也容易进入不好的鞍点，故而我们需要用更小的 batch size 从而引入更强的随机性，实验中默认使用32的 batch size。小幅度提升。  
5.各层的学习率一致。之前的不少文章中都提出，基础层的学习率小一些，新增层的学习率大一些会比较好，在很多分类网络中也较为常见，PCB 中也采用这种方案，这样也能防止模型训练崩溃，而根据我们的实验结果，整个网络采用完全一致的学习率会取得更好的性能。小幅度提升。
